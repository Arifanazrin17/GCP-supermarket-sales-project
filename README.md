# GCP-supermarket-sales-project
üèóÔ∏è GCP Architecture

1. Data Sources (Supermarket Transactions)
Simulated POS system generates sales data (CSV/JSON files, or streaming events like Pub/Sub).
Two types of data:
Transactional data ‚Üí product sales,  stores
2. Ingestion Layer
*Batch Ingestion*: Upload daily CSV/JSON sales files ‚Üí Cloud Storage (GCS) (Raw zone).
*Streaming Ingestion*: Real-time sales messages ‚Üí Pub/Sub.
3. Processing Layer
*Cloud Functions* (triggered by GCS upload):
  -Validate & clean CSV.
  -Load into BigQuery staging tables.
*Dataflow (Apache Beam)* ‚Üí transforms raw data from Pub/Sub ‚Üí write into BigQuery (streaming pipeline).
BigQuery ‚Üí ELT transformations (SQL-based modeling).
4. Orchestration
*Cloud Composer (Airflow)* ‚Üí schedule:
Move data from GCS ‚Üí BigQuery
Trigger Dataflow jobs
Run validation checks
Refresh Looker dashboards
5. Data Warehouse / Analytics Layer
*BigQuery* ‚Üí main analytical data warehouse.
Create fact tables (sales, payments) and dimension tables (products, customers, stores).
Build star schema for reporting.
6. Visualization
*Looker Studio* / Looker ‚Üí dashboards:
Daily Sales Trend
Top 10 Products by Revenue
Store Performance Comparison
Customer Segmentation
7. Monitoring & Governance (**pipeline in future)
Cloud Monitoring / Logging ‚Üí monitor pipeline health.
IAM ‚Üí restrict access (e.g., analysts can only query curated datasets).
Data Catalog ‚Üí document datasets.
-----------------------------------------------------------------------------------------------------------
This project will help you practice:  
Data ingestion (batch + streaming)  
Data storage (raw vs. curated)  
Data transformation (ETL/ELT pipelines)  
Orchestration (Airflow)  
Data modeling &amp; analytics (BigQuery, Looker)  
Monitoring &amp; security (IAM, Logging, Monitoring) **planned in future
-----------------------------------------------------------------------------------------------------------
